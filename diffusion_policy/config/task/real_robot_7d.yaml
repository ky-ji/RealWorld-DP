name: real_robot_7d

# Original video resolution is 1920x1080
# We'll downsample to 320x180 for training (keeping aspect ratio)
image_shape: [3, 180, 320]
dataset_path: /home/kyji/storage_net/realworld_eval/realworld_data/1119/diffusion_policy_dataset

shape_meta: &shape_meta
  # acceptable types: rgb, low_dim
  obs:
    camera_0:
      shape: ${task.image_shape}
      type: rgb
    robot_eef_pose:
      shape: [7]
      type: low_dim
  action:
    shape: [7]

env_runner:
  _target_: diffusion_policy.env_runner.real_pusht_image_runner.RealPushTImageRunner

dataset:
  _target_: diffusion_policy.dataset.real_pusht_image_dataset.RealPushTImageDataset
  shape_meta: *shape_meta
  dataset_path: ${task.dataset_path}
  horizon: ${horizon}
  pad_before: ${eval:'${n_obs_steps}-1+${n_latency_steps}'}
  pad_after: ${eval:'${n_action_steps}-1'}
  n_obs_steps: ${dataset_obs_steps}
  n_latency_steps: ${n_latency_steps}
  use_cache: True
  seed: 42
  val_ratio: 0.1
  max_train_episodes: null
  delta_action: True  # 启用相对位姿，缓解观测-动作对齐问题
